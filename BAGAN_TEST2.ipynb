{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cznH_AoIxzTA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cD9m_TCRxzTF"
   },
   "source": [
    "## BAGAN BatchGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oE4djFhbxzTG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(C) Copyright IBM Corporation 2018\n",
    "All rights reserved. This program and the accompanying materials\n",
    "are made available under the terms of the Eclipse Public License v1.0\n",
    "which accompanies this distribution, and is available at\n",
    "http://www.eclipse.org/legal/epl-v10.html\n",
    "\"\"\"\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class BatchGenerator:\n",
    "\n",
    "    TRAIN = 1\n",
    "    TEST = 0\n",
    "\n",
    "    def __init__(self, data_src, batch_size=32, class_to_prune=None, unbalance=0, dataset='MNIST'):\n",
    "        assert dataset in ('MNIST', 'CIFAR10'), 'Unknown dataset: ' + dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.data_src = data_src\n",
    "\n",
    "        # Load data\n",
    "        if dataset == 'MNIST':\n",
    "            mnist = input_data.read_data_sets(\"dataset/mnist\", one_hot=False)\n",
    "\n",
    "            assert self.batch_size > 0, 'Batch size has to be a positive integer!'\n",
    "\n",
    "            if self.data_src == self.TEST:\n",
    "                self.dataset_x = mnist.test.images\n",
    "                self.dataset_y = mnist.test.labels\n",
    "            else:\n",
    "                self.dataset_x = mnist.train.images\n",
    "                self.dataset_y = mnist.train.labels\n",
    "\n",
    "            # Normalize between -1 and 1\n",
    "            self.dataset_x = (np.reshape(self.dataset_x, (self.dataset_x.shape[0], 28, 28)) - 0.5) * 2\n",
    "\n",
    "            # Include 1 single color channel\n",
    "            self.dataset_x = np.expand_dims(self.dataset_x, axis=1)\n",
    "\n",
    "        elif dataset == 'CIFAR10':\n",
    "            ((x, y), (x_test, y_test)) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "            if self.data_src == self.TEST:\n",
    "                self.dataset_x = x_test\n",
    "                self.dataset_y = y_test\n",
    "            else:\n",
    "                self.dataset_x = x\n",
    "                self.dataset_y = y\n",
    "\n",
    "            # Arrange x: channel first\n",
    "            self.dataset_x = np.transpose(self.dataset_x, axes=(0, 3, 1, 2))\n",
    "\n",
    "            # Normalize between -1 and 1\n",
    "            self.dataset_x = self.dataset_x/255 - 0.5\n",
    "\n",
    "            # Y 1D format\n",
    "            self.dataset_y = self.dataset_y[:, 0]\n",
    "\n",
    "        assert (self.dataset_x.shape[0] == self.dataset_y.shape[0])\n",
    "\n",
    "        # Compute per class instance count.\n",
    "        classes = np.unique(self.dataset_y)\n",
    "        self.classes = classes\n",
    "        per_class_count = list()\n",
    "        for c in classes:\n",
    "            per_class_count.append(np.sum(np.array(self.dataset_y == c)))\n",
    "\n",
    "        # Prune if needed!\n",
    "        if class_to_prune is not None:\n",
    "            all_ids = list(np.arange(len(self.dataset_x)))\n",
    "\n",
    "            mask = [class_to_prune == lc for lc in self.dataset_y]\n",
    "            all_ids_c = np.array(all_ids)[mask]\n",
    "            np.random.shuffle(all_ids_c)\n",
    "\n",
    "            other_class_count = np.array(per_class_count)\n",
    "            other_class_count = np.delete(other_class_count, class_to_prune)\n",
    "            to_keep = int(np.ceil(unbalance * max(\n",
    "                other_class_count)))\n",
    "\n",
    "            to_delete = all_ids_c[to_keep: len(all_ids_c)]\n",
    "\n",
    "            self.dataset_x = np.delete(self.dataset_x, to_delete, axis=0)\n",
    "            self.dataset_y = np.delete(self.dataset_y, to_delete, axis=0)\n",
    "\n",
    "        # Recount after pruning\n",
    "        per_class_count = list()\n",
    "        for c in classes:\n",
    "            per_class_count.append(np.sum(np.array(self.dataset_y == c)))\n",
    "        self.per_class_count = per_class_count\n",
    "\n",
    "        # List of labels\n",
    "        self.label_table = [str(c) for c in range(10)]\n",
    "\n",
    "        # Preload all the labels.\n",
    "        self.labels = self.dataset_y[:]\n",
    "\n",
    "        # per class ids\n",
    "        self.per_class_ids = dict()\n",
    "        ids = np.array(range(len(self.dataset_x)))\n",
    "        for c in classes:\n",
    "            self.per_class_ids[c] = ids[self.labels == c]\n",
    "\n",
    "    def get_samples_for_class(self, c, samples=None):\n",
    "        if samples is None:\n",
    "            samples = self.batch_size\n",
    "\n",
    "        np.random.shuffle(self.per_class_ids[c])\n",
    "        to_return = self.per_class_ids[c][0:samples]\n",
    "        return self.dataset_x[to_return]\n",
    "\n",
    "    def get_label_table(self):\n",
    "        return self.label_table\n",
    "\n",
    "    def get_num_classes(self):\n",
    "        return len( self.label_table )\n",
    "\n",
    "    def get_class_probability(self):\n",
    "        return self.per_class_count/sum(self.per_class_count)\n",
    "    \n",
    "    def get_class_numberOfSamples(self):\n",
    "        return self.per_class_count\n",
    "\n",
    "    ### ACCESS DATA AND SHAPES ###\n",
    "    def get_num_samples(self):\n",
    "        return self.dataset_x.shape[0]\n",
    "\n",
    "    def get_image_shape(self):\n",
    "        return [self.dataset_x.shape[1], self.dataset_x.shape[2], self.dataset_x.shape[3]]\n",
    "\n",
    "    def next_batch(self):\n",
    "        dataset_x = self.dataset_x\n",
    "        labels = self.labels\n",
    "\n",
    "        indices = np.arange(dataset_x.shape[0])\n",
    "\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for start_idx in range(0, dataset_x.shape[0] - self.batch_size + 1, self.batch_size):\n",
    "            access_pattern = indices[start_idx:start_idx + self.batch_size]\n",
    "            access_pattern = sorted(access_pattern)\n",
    "\n",
    "            yield dataset_x[access_pattern, :, :, :], labels[access_pattern]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WsOKw_cyxzTM"
   },
   "source": [
    "## User-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A-As-7AtxzTO"
   },
   "outputs": [],
   "source": [
    "# unbalance_class_images = np.empty((1, 28, 28))\n",
    "\n",
    "def get_unbalanceClass_x(x_train, y_train):\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(x_train)):\n",
    "        if y_train[i]==1:\n",
    "            count = count+1\n",
    "            if count == 1:\n",
    "                unbalance_x = x_train[i]\n",
    "                unbalance_x = np.expand_dims(unbalance_x, axis=0)\n",
    "                \n",
    "            else:\n",
    "                unbalance_x = np.append(unbalance_x, np.expand_dims(x_train[i], axis=0), axis=0)\n",
    "                \n",
    "                \n",
    "                \n",
    "    #unbalance_x = np.expand_dims(unbalance_x, axis=0)\n",
    "    return unbalance_x\n",
    "\n",
    "\n",
    "def get_unbalanceClass_y(unbalance_x):\n",
    "    unbalance_y = np.array(np.repeat(1, len(unbalance_x)))\n",
    "    return unbalance_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5JovLvVxzTT"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# mode==1 for 'MNIST' and mode==2 for CIFAR10\n",
    "def show_generated_samples(unbalance_x, unbalance_y, mode):\n",
    "\n",
    "    datagen = ImageDataGenerator(featurewise_center=True, \n",
    "                                 featurewise_std_normalization=True,\n",
    "                                 rotation_range=10, \n",
    "                                 zoom_range=0.1)\n",
    "    \n",
    "    # fit the data\n",
    "    datagen.fit(unbalance_x)\n",
    "    for x_batch in datagen.flow(unbalance_x, unbalance_y):\n",
    "        for i in range(0, 9):\n",
    "            plt.subplot(330 + 1 + i)\n",
    "            if mode==1:\n",
    "                plt.imshow(unbalance_x[i])\n",
    "            if mode==2:\n",
    "                plt.imshow(unbalance_x[i])\n",
    "        plt.show()\n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N8L759kSxzTZ"
   },
   "source": [
    "## Generate training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SE-p_f9rxzTa"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "unbalance = 0.05\n",
    "dataset_name = 'CIFAR10'\n",
    "# Unbalance the training set.\n",
    "bg_train_partial = BatchGenerator(BatchGenerator.TEST, batch_size, class_to_prune=1, unbalance=unbalance, dataset=dataset_name)\n",
    "bg_train_partial.get_class_numberOfSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0E-vylcexzTg",
    "outputId": "e9d5d1ca-a59f-44f5-bfc1-56a72d1e8be1"
   },
   "outputs": [],
   "source": [
    "x_train_unbalanced = bg_train_partial.dataset_x.transpose(0,2,3,1)\n",
    "y_train_unbalanced = bg_train_partial.dataset_y\n",
    "x_train_unbalanced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlrzOrHrxzTl"
   },
   "source": [
    "## Generate test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "syv-GMk7xzTn",
    "outputId": "87e36a7c-241b-4e1a-e983-8a48af500995"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "unbalance = 0.05\n",
    "dataset_name = 'CIFAR10'\n",
    "# Unbalance the training set.\n",
    "bg_test_partial = BatchGenerator(BatchGenerator.TRAIN, batch_size, class_to_prune=1, unbalance=unbalance, dataset=dataset_name)\n",
    "bg_test_partial.get_class_numberOfSamples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yivQSFqYxzTp",
    "outputId": "eb9d5d9c-cbc5-407d-bc4e-9c8e95fbc395"
   },
   "outputs": [],
   "source": [
    "x_test_unbalanced = bg_test_partial.dataset_x.transpose(0,2,3,1)\n",
    "y_test_unbalanced = bg_test_partial.dataset_y\n",
    "x_test_unbalanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5sGxN6QtxzTs"
   },
   "outputs": [],
   "source": [
    "## Take all images of unbalanced class to test the classifier after training them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYaA6xQSxzTy"
   },
   "outputs": [],
   "source": [
    "bg_test = BatchGenerator(BatchGenerator.TRAIN, batch_size, class_to_prune=2, unbalance=unbalance, dataset=dataset_name)\n",
    "\n",
    "x = bg_test.dataset_x.transpose(0,2,3,1)\n",
    "y = bg_test.dataset_y\n",
    "\n",
    "images_to_test_x = get_unbalanceClass_x(x, y)\n",
    "images_to_test_y = get_unbalanceClass_y(images_to_test_x, y)\n",
    "images_to_test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JHsZfkbfxzT2"
   },
   "source": [
    "## Unbalanced dataset with the class 1 (cars) with 95% of its samples pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gbgzY_KQxzT3",
    "outputId": "7a58277c-b39c-4837-e698-90b8dcbeae05"
   },
   "outputs": [],
   "source": [
    "bg_train_partial.get_class_numberOfSamples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27NnPlzlxzT5"
   },
   "source": [
    "## Get images from the unbalanced class and visualize some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DUGPaTyxzT6"
   },
   "outputs": [],
   "source": [
    "unbalanced_class_x = get_unbalanceClass_x(x_train_unbalanced, y_train_unbalanced)\n",
    "unbalanced_class_y = get_unbalanceClass_y(unbalanced_class_x)\n",
    "unbalanced_class_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fgDQU0sxzT7"
   },
   "outputs": [],
   "source": [
    "show_generated_samples(unbalanced_class_x, unbalanced_class_y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vzxW43XCxzT9"
   },
   "source": [
    "## Data augmentation using basic transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCt1O1GGxzUB"
   },
   "outputs": [],
   "source": [
    "# Define Transformations:\n",
    "\n",
    "# Horizontal Shift Augmentation (pixels range)\n",
    "datagen1 = ImageDataGenerator(width_shift_range=[-10,10])\n",
    "# Vertical Shift Augmentation (pixels range)\n",
    "datagen2 = ImageDataGenerator(height_shift_range=0.5)\n",
    "\n",
    "# Horizontal and Vertical Flip Augmentation\n",
    "datagen3 = ImageDataGenerator(horizontal_flip=True)\n",
    "# Vertical Flip Augmentation\n",
    "datagen4 = ImageDataGenerator(vertical_flip=True)\n",
    "\n",
    "# Random Rotation Augmentation\n",
    "datagen5 = ImageDataGenerator(rotation_range=60)\n",
    "\n",
    "# Random Brightness Augmentation\n",
    "datagen6 = ImageDataGenerator(brightness_range=[1.0,1.8])\n",
    "# Random Darkness Augmentation\n",
    "datagen7 = ImageDataGenerator(brightness_range=[0.2,1.0])\n",
    "\n",
    "# Random Zoom-In Augmentation\n",
    "datagen8 = ImageDataGenerator(zoom_range=[0.5,1.0])\n",
    "# Random Zoom-Out Augmentation\n",
    "datagen9 = ImageDataGenerator(zoom_range=[1.0,1.5])\n",
    "\n",
    "datagens = [datagen1, datagen2, datagen3, datagen4, datagen5, datagen6, datagen7, datagen8, datagen9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxr0JfVnxzUD"
   },
   "outputs": [],
   "source": [
    "# Initialize collection\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "\n",
    "collection = np.empty(shape=(1, 32, 32, 3)) \n",
    "\n",
    "for i in range(len(unbalanced_class_x)):\n",
    "    img = array_to_img(unbalanced_class_x[i])\n",
    "    # convert to numpy array\n",
    "    data = img_to_array(img)\n",
    "    print(\"Images from image: {}\".format(i))\n",
    "        \n",
    "    # expand dimension to one sample\n",
    "    samples = expand_dims(data, 0)\n",
    "    \n",
    "    for transformation in range(len(datagens)):\n",
    "        # get a datagen\n",
    "        datagen = datagens[transformation]\n",
    "        # prepare iterator\n",
    "        it = datagen.flow(samples, batch_size=1)\n",
    "        # generate samples and plot\n",
    "        # for i in range(9):\n",
    "        # define subplot\n",
    "        pyplot.subplot(330 + 1 + transformation)\n",
    "        # generate batch of images\n",
    "        batch = it.next()\n",
    "        \n",
    "        # convert to unsigned integers for viewing\n",
    "        image = batch[0].astype('uint8')\n",
    "        \n",
    "        # expand dimension to one sample to save it in np array (X, 32, 32, 3)\n",
    "        new_image = expand_dims(image, 0)\n",
    "        collection = np.append(collection, new_image, axis=0)\n",
    "        \n",
    "        #### Uncomment to plot generated images\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "    # show the figure\n",
    "    pyplot.show()\n",
    "\n",
    "# Remove first element of the initialized collection\n",
    "collection = np.delete(collection,0, 0)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rLopiHMxxzUB"
   },
   "source": [
    "## Include the generated images in the dataset before doing the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UaaIJlHqxzUK",
    "outputId": "aed2420c-fd87-472b-bedf-6fd465d8410e"
   },
   "outputs": [],
   "source": [
    "def append_image_collections(unbalanced, generated):\n",
    "    balanced_class_x = np.append(unbalanced, generated, axis=0)\n",
    "    return balanced_class_x\n",
    "\n",
    "# Append the generated images to the hole dataset\n",
    "x_train_balanced = append_image_collections(x_train_unbalanced, collection)\n",
    "print(x_train_balanced.shape)\n",
    "\n",
    "# Generate array of 1s (class of the generated images) and attach it to the big one\n",
    "y_collection = np.array(np.repeat(1, len(collection)))\n",
    "y_train_balanced = np.append(y_train_unbalanced, y_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lsNwq8eL7P2t",
    "outputId": "670be46b-eb7c-4d68-ec6f-a57765428f48"
   },
   "outputs": [],
   "source": [
    "print(y_train_balanced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hWxAhYZjxzUL"
   },
   "source": [
    "## Import images generated using BAGAN and append them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qZx4h1YxxzUL"
   },
   "outputs": [],
   "source": [
    "# Do for Train (I think not for test)\n",
    "x_train_balanced_gan = append_generated_images(unbalanced_train_x, generated_train_x)\n",
    "y_train_balanced_gan = np.array(np.repeat(1, len(x_train_balanced)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QaXanWcSxzUN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "26MWHLGNxzUO"
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOc9WbpTxzUO"
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "\n",
    "    # Data pre-processing\n",
    "    x = x.astype('float32')\n",
    "    x /= 255.0\n",
    "    \n",
    "    # One-hot encoding\n",
    "    from keras.utils import np_utils\n",
    "    y = np_utils.to_categorical(y, num_classes)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3iq67XyxzUP"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "# Unbalanced dataset\n",
    "x_train_unbalanced, y_train_unbalanced = preprocess(x_train_unbalanced, y_train_unbalanced)\n",
    "# Balanced with basic transformations\n",
    "x_train_balanced, y_train_balanced = preprocess(x_train_balanced, y_train_balanced)\n",
    "# Balanced with BAGAN transformations\n",
    "# x_train_balanced_gan, y_train_balanced_gan = preprocess (x_train_balanced_gan, y_train_balanced_gan)\n",
    "\n",
    "# Testing data\n",
    "# Unbalanced dataset\n",
    "x_test_unbalanced, y_test_unbalanced = preprocess(x_test_unbalanced, y_test_unbalanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ob9QkvYxzUQ"
   },
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "32h1Wdf_xzUQ"
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "-00XUQmkxzUQ",
    "outputId": "a5040ae4-192a-4edf-c182-1d009df340fd"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train_unbalanced.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model2 = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jntmfcaTxzUR"
   },
   "source": [
    "## Training the 3 alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qznMv9zhxzUS",
    "outputId": "afe69f06-bc7f-45b9-c2a8-788342cd7bab"
   },
   "outputs": [],
   "source": [
    "# Unbalanced\n",
    "data = model.fit(x_train_unbalanced, y_train_unbalanced, batch_size=16, epochs=20, verbose=2)\n",
    "# Balanced classic\n",
    "data = model2.fit(x_train_balanced, y_train_balanced, batch_size=16, epochs=20, verbose=2)\n",
    "# Balanced BAGAN\n",
    "# data = model.fit(x_train, y_train, batch_size=16, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDyP83n7xzUT"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "HPI5e-JVxzUT",
    "outputId": "093feef2-d4c2-4845-bae5-36c5dd24e423"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Unbalanced\n",
    "start_unbalanced = time()\n",
    "loss_unbalanced, acc_unbalanced = model.evaluate(x_test_unbalanced, y_test_unbalanced, verbose=0)\n",
    "end_unbalanced = time()\n",
    "print('CNN took ' + str(end_unbalanced - start_unbalanced) + ' seconds')\n",
    "print('Test loss: ' + str(loss_unbalanced) + ' - Accuracy: ' + str(acc_unbalanced))\n",
    "\n",
    "# Balanced classic\n",
    "start_balanced = time()\n",
    "loss_balanced, acc_balanced = model2.evaluate(x_test_unbalanced, y_test_unbalanced, verbose=0)\n",
    "end_balanced = time()\n",
    "print('CNN took ' + str(end_balanced - start_balanced) + ' seconds')\n",
    "print('Test loss: ' + str(loss_balanced) + ' - Accuracy: ' + str(acc_balanced))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BAGAN_TEST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
